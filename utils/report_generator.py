import json
import pandas as pd
import os
from datetime import datetime
from typing import List, Dict
from config import MODEL_PRICING

class ReportGenerator:
    def __init__(self, results_dir: str):
        self.results_dir = results_dir
        
    def generate_report(self, run_results: List[Dict], cost_df: pd.DataFrame):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. Save Raw JSON
        raw_path = os.path.join(self.results_dir, f"raw_results_{timestamp}.json")
        with open(raw_path, 'w', encoding='utf-8') as f:
            json.dump(run_results, f, ensure_ascii=False, indent=2)
            
        # 2. Process Data for Analysis
        flattened_data = []
        for r in run_results:
            row = r.get("metrics", {}).copy()
            row["model"] = r["model"]
            row["task"] = r["task"]
            row["success"] = r["success"]
            # Flatten some nested metrics if needed, but current metrics are flat
            flattened_data.append(row)
            
        results_df = pd.DataFrame(flattened_data)
        
        # 3. Generate Markdown Report (User Requested Format)
        md = f"# LLM Î™®Îç∏ ÌèâÍ∞Ä Î¶¨Ìè¨Ìä∏ üìä\n\n**ÏÉùÏÑ± ÏùºÏãú**: {timestamp}\n\n"
        
        # --- 2. ÌÉúÏä§ÌÅ¨ ÌäπÌôî ÌèâÍ∞Ä ---
        md += "### 2. ÌÉúÏä§ÌÅ¨ ÌäπÌôî ÌèâÍ∞Ä\n"
        
        # 2.1 Íµ¨Ï°∞ÌôîÎêú Ï∂úÎ†• ÏÉùÏÑ± Îä•Î†•
        md += "#### 1. Íµ¨Ï°∞ÌôîÎêú Ï∂úÎ†• ÏÉùÏÑ± Îä•Î†•\n"
        md += "- JSON ÌòïÏãù Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± Ï†ïÌôïÎèÑ Î∞è ÌïÑÏàò ÌïÑÎìú ÎàÑÎùΩ Ïó¨Î∂Ä ÌèâÍ∞Ä\n"
        if not results_df.empty:
            # Parsing Error Rate = 1 - json_validity
            # Field Completeness
            struct_cols = ["json_validity", "field_completeness"]
            struct_cols = [c for c in struct_cols if c in results_df.columns]
            
            if struct_cols:
                struct_perf = results_df.groupby("model")[struct_cols].mean()
                # Calculate Parsing Error Rate
                if "json_validity" in struct_perf.columns:
                    struct_perf["parsing_error_rate"] = 1.0 - struct_perf["json_validity"]
                    
                md += struct_perf.to_markdown(floatfmt=".4f") + "\n\n"
            else:
                 md += "Í¥ÄÎ†® Î©îÌä∏Î¶≠ Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå.\n\n"
        else:
            md += "Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå.\n\n"

        # 2.2 ÏùºÍ¥ÄÏÑ±
        md += "#### 2. ÏùºÍ¥ÄÏÑ±\n"
        md += "- Í∞ôÏùÄ ÏûÖÎ†•Ïóê ÎåÄÌï¥ Ïó¨Îü¨ Î≤à Ïã§ÌñâÌñàÏùÑ ÎïåÏùò ÏùºÍ¥ÄÏÑ± (Temperature=0, 3Ìöå Î∞òÎ≥µ Ï∏°Ï†ï)\n"
        if "consistency" in results_df.columns:
            consistency_perf = results_df.groupby("model")[["consistency"]].mean()
            md += consistency_perf.to_markdown(floatfmt=".4f") + "\n\n"
        else:
             md += "ÏùºÍ¥ÄÏÑ± Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå.\n\n"
             
        # 2.3 Ï∂îÎ°† ÌíàÏßà
        md += "#### 3. Ï∂îÎ°† ÌíàÏßà\n"
        md += "- ÌéòÎ•¥ÏÜåÎÇò ÌäπÏÑ± Î∞òÏòÅ Î∞è CoT Ï∂îÎ°† Í≥ºÏ†ï ÌèâÍ∞Ä\n"
        # Combine reasoning quality metrics
        reasoning_cols = ["cot_quality", "reasoning_quality", "rating_appropriateness", "explanation_quality"]
        reasoning_cols = [c for c in reasoning_cols if c in results_df.columns]
        
        if reasoning_cols:
             reasoning_perf = results_df.groupby("model")[reasoning_cols].mean()
             md += reasoning_perf.to_markdown(floatfmt=".4f") + "\n\n"
        else:
             md += "Ï∂îÎ°† ÌíàÏßà Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå.\n\n"

        # --- 3. Ïã§Ïö©Ï†Å Ï†úÏïΩÏÇ¨Ìï≠ ---
        md += "### 3. Ïã§Ïö©Ï†Å Ï†úÏïΩÏÇ¨Ìï≠\n"
        
        if not cost_df.empty:
            # 3.1 ÏùëÎãµ ÏÜçÎèÑ
            md += "#### 1. ÏùëÎãµ ÏÜçÎèÑ(Latency)\n"
            latency_stats = cost_df.groupby("model")["latency_ms"].agg(['mean']).rename(columns={'mean': 'avg_latency_ms'})
            md += latency_stats.to_markdown(floatfmt=".2f") + "\n\n"
            
            # 3.2 Cost
            md += "#### 2. Cost\n"
            
            # Prepare Cost Table
            cost_data = []
            models = cost_df["model"].unique()
            
            for m in models:
                m_df = cost_df[cost_df["model"] == m]
                avg_cost_req = m_df["cost_usd"].mean()
                monthly = avg_cost_req * 10000
                
                total_input = m_df["input_tokens"].sum()
                total_output = m_df["output_tokens"].sum()
                
                if total_output > 0:
                     ratio_val = total_input / total_output
                     io_ratio = f"{ratio_val:.1f}:1"
                else:
                    io_ratio = "N/A"
                
                # Pricing Info
                pricing = MODEL_PRICING.get(m, "N/A")
                if isinstance(pricing, dict):
                     pricing_str = f"In:${pricing.get('input')}/Out:${pricing.get('output')}"
                else:
                     pricing_str = str(pricing)
                
                cost_data.append({
                    "model": m,
                    "avg_cost_per_req": avg_cost_req,
                    "monthly_projection(10k)": monthly,
                    "token_price_1M": pricing_str,
                    "io_token_ratio_input_output": io_ratio
                })
                
            cost_summary_df = pd.DataFrame(cost_data).set_index("model")
            md += cost_summary_df.to_markdown(floatfmt=".6f") + "\n\n"
            
        else:
            md += "ÎπÑÏö© Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå.\n\n"

        
        report_path = os.path.join(self.results_dir, f"report_{timestamp}.md")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(md)
            
        print(f"Reports generated: \n - {raw_path}\n - {report_path}")
