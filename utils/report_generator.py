import json
import pandas as pd
import os
from datetime import datetime
from typing import List, Dict
from config import MODEL_PRICING


class ReportGenerator:
    def __init__(self, results_dir: str):
        self.results_dir = results_dir

    def generate_report(self, run_results: List[Dict], cost_df: pd.DataFrame):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # 1. Save Raw JSON
        raw_path = os.path.join(self.results_dir, f"raw_results_{timestamp}.json")
        with open(raw_path, "w", encoding="utf-8") as f:
            json.dump(run_results, f, ensure_ascii=False, indent=2)

        # 2. Process Data for Analysis
        flattened_data = []
        for r in run_results:
            row = r.get("metrics", {}).copy()
            row["model"] = r["model"]
            row["task"] = r["task"]
            row["success"] = r["success"]
            # Flatten some nested metrics if needed, but current metrics are flat
            flattened_data.append(row)

        results_df = pd.DataFrame(flattened_data)

        # 3. Generate Markdown Report (User Requested Format)
        md = f"# LLM Î™®Îç∏ ÌèâÍ∞Ä Î¶¨Ìè¨Ìä∏ üìä\n\n**ÏÉùÏÑ± ÏùºÏãú**: {timestamp}\n\n"

        # --- 2. ÌÉúÏä§ÌÅ¨ ÌäπÌôî ÌèâÍ∞Ä ---
        md += "### 2. ÌÉúÏä§ÌÅ¨ ÌäπÌôî ÌèâÍ∞Ä\n"

        # --- 2. ÏÉÅÏÑ∏ ÌíàÏßà ÌèâÍ∞Ä (Advanced Metrics) ---
        md += "### 2. ÌíàÏßà ÏÉÅÏÑ∏ ÌèâÍ∞Ä (Quality Metrics)\n\n"

        # 2.1 Í∏∞Î≥∏ Íµ¨Ï°∞ Í±¥Ï†ÑÏÑ±
        md += "#### 1. Í∏∞Î≥∏ Íµ¨Ï°∞ Í±¥Ï†ÑÏÑ± (Structural Health)\n"
        md += "- **Parsing Error Rate**: JSON ÌååÏã± Ïã§Ìå® ÎπÑÏú® (ÎÇÆÏùÑÏàòÎ°ù Ï¢ãÏùå)\n"
        md += "- **Field Completeness**: ÌïÑÏàò ÌïÑÎìú(Ïù¥Î¶Ñ, ÎÇòÏù¥, Î∂ÑÏÑù Îì±)Í∞Ä Î™®Îëê Ï°¥Ïû¨ÌïòÎäîÏßÄ (1.0 = ÏôÑÎ≤Ω)\n"
        md += "- **Schema Compliance**: Îç∞Ïù¥ÌÑ∞ ÌÉÄÏûÖ(Î¶¨Ïä§Ìä∏, Î¨∏ÏûêÏó¥ Îì±) Ï§ÄÏàò Ïó¨Î∂Ä (1.0 = Ï§ÄÏàò)\n\n"

        struct_cols = [
            "json_validity",
            "field_completeness",
            "schema_compliance",
            "value_accuracy",
        ]
        struct_cols = [c for c in struct_cols if c in results_df.columns]

        if struct_cols:
            struct_perf = results_df.groupby("model")[struct_cols].mean()
            if "json_validity" in struct_perf.columns:
                struct_perf["parsing_error_rate"] = 1.0 - struct_perf["json_validity"]
            md += struct_perf.to_markdown(floatfmt=".4f") + "\n\n"

        # 2.2 ÌéòÎ•¥ÏÜåÎÇò ÏÉùÏÑ± ÌíàÏßà (ÌïµÏã¨ ÏßÄÌëú)
        md += "#### 2. ÌéòÎ•¥ÏÜåÎÇò ÏÉùÏÑ± ÌíàÏßà (Persona Quality - ÌïµÏã¨)\n"
        md += "**Ïù¥ ÏÑπÏÖòÏùÄ Î™®Îç∏Ïù¥ ÏñºÎßàÎÇò 'ÏÇ¨Îûå Í∞ôÏùÄ' ÌéòÎ•¥ÏÜåÎÇòÎ•º ÎßåÎì§ÏóàÎäîÏßÄ ÌèâÍ∞ÄÌï©ÎãàÎã§.**\n\n"
        md += "- **CoT Depth Score (Ï∂îÎ°† ÍπäÏù¥)**: Îã®Ïàú Îç∞Ïù¥ÌÑ∞ ÎÇòÏó¥Ïù¥ ÏïÑÎãå, 'Ïôú' Í∑∏Îü∞ Ï∑®Ìñ•ÏùÑ Í∞ÄÏ°åÎäîÏßÄÏóê ÎåÄÌïú ÎÖºÎ¶¨Ï†Å Ïó∞Í≤∞ ÍπäÏù¥ (0.0~1.0). (ÎÜíÏùÑÏàòÎ°ù Ï¢ãÏùå)\n"
        md += "- **Persona Specificity (Íµ¨Ï≤¥ÏÑ±)**: ÌéòÎ•¥ÏÜåÎÇòÍ∞Ä Íµ¨Ï≤¥Ï†ÅÏù∏ ÏÉÅÌô©(Ï£ºÎßê, Ìá¥Í∑º, Îç∞Ïù¥Ìä∏ Îì±), Í∞êÏ†ï, ÎùºÏù¥ÌîÑÏä§ÌÉÄÏùº Îß•ÎùΩÏùÑ Ìè¨Ìï®ÌïòÎäîÏßÄ (0.0~1.0). (ÎÜíÏùÑÏàòÎ°ù Ï¢ãÏùå)\n"
        md += "- **Safety Consistency (ÏïàÏ†ÑÏÑ±/ÏùºÍ¥ÄÏÑ±)**: ÏûÖÎ†•Îêú ÏïåÎü¨ÏßÄ Ï†ïÎ≥¥Î•º ÎàÑÎùΩÌïòÍ±∞ÎÇò Î™®ÏàúÎêú ÏãùÏäµÍ¥Ä(ÏïåÎü¨ÏßÄ Ïû¨Î£å ÏÑ†Ìò∏ Îì±)ÏùÑ ÏÉùÏÑ±ÌïòÏßÄ ÏïäÏïòÎäîÏßÄ (1.0 = ÏïàÏ†Ñ). (Îß§Ïö∞ Ï§ëÏöî)\n\n"

        quality_cols = ["cot_depth_score", "persona_specificity", "safety_consistency"]
        quality_cols = [c for c in quality_cols if c in results_df.columns]

        if quality_cols:
            quality_perf = results_df.groupby("model")[quality_cols].mean()
            md += quality_perf.to_markdown(floatfmt=".4f") + "\n\n"

        # 2.3 ÏùºÍ¥ÄÏÑ±
        md += "#### 3. ÏÉùÏÑ± ÏùºÍ¥ÄÏÑ± (Consistency)\n"
        md += "- **Consistency**: Í∞ôÏùÄ ÏûÖÎ†•Ïóê ÎåÄÌï¥ Ïó¨Îü¨ Î≤à Ïã§ÌñâÌñàÏùÑ Îïå Ï£ºÏöî ÏÜçÏÑ±(Ïù¥Î¶Ñ, ÏïåÎü¨ÏßÄ Îì±)Ïù¥ Ïú†ÏßÄÎêòÎäîÏßÄ (1.0 = ÏôÑÎ≤ΩÌûà ÎèôÏùº)\n"
        if "consistency" in results_df.columns:
            consistency_perf = results_df.groupby("model")[["consistency"]].mean()
            md += consistency_perf.to_markdown(floatfmt=".4f") + "\n\n"

        # --- 3. Ïã§Ïö©Ï†Å Ï†úÏïΩÏÇ¨Ìï≠ ---
        md += "### 3. Ïã§Ïö©Ï†Å Ï†úÏïΩÏÇ¨Ìï≠\n"

        if not cost_df.empty:
            # 3.1 ÏùëÎãµ ÏÜçÎèÑ
            md += "#### 1. ÏùëÎãµ ÏÜçÎèÑ(Latency)\n"
            latency_stats = (
                cost_df.groupby("model")["latency_ms"]
                .agg(["mean"])
                .rename(columns={"mean": "avg_latency_ms"})
            )
            md += latency_stats.to_markdown(floatfmt=".2f") + "\n\n"

            # 3.2 Cost
            md += "#### 2. Cost\n"

            # Prepare Cost Table
            cost_data = []
            models = cost_df["model"].unique()

            for m in models:
                m_df = cost_df[cost_df["model"] == m]
                avg_cost_req = m_df["cost_usd"].mean()
                monthly = avg_cost_req * 10000

                total_input = m_df["input_tokens"].sum()
                total_output = m_df["output_tokens"].sum()

                if total_output > 0:
                    ratio_val = total_input / total_output
                    io_ratio = f"{ratio_val:.1f}:1"
                else:
                    io_ratio = "N/A"

                # Pricing Info
                pricing = MODEL_PRICING.get(m, "N/A")
                if isinstance(pricing, dict):
                    pricing_str = (
                        f"In:${pricing.get('input')}/Out:${pricing.get('output')}"
                    )
                else:
                    pricing_str = str(pricing)

                cost_data.append(
                    {
                        "model": m,
                        "avg_cost_per_req": avg_cost_req,
                        "monthly_projection(10k)": monthly,
                        "token_price_1M": pricing_str,
                        "io_token_ratio_input_output": io_ratio,
                    }
                )

            cost_summary_df = pd.DataFrame(cost_data).set_index("model")
            md += cost_summary_df.to_markdown(floatfmt=".6f") + "\n\n"

        else:
            md += "ÎπÑÏö© Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå.\n\n"

        report_path = os.path.join(self.results_dir, f"report_{timestamp}.md")
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(md)

        print(f"Reports generated: \n - {raw_path}\n - {report_path}")
